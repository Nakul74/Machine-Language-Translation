{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1563,
     "status": "ok",
     "timestamp": 1623679621421,
     "user": {
      "displayName": "NAKUL CHAMARIYA",
      "photoUrl": "",
      "userId": "06259338779627162060"
     },
     "user_tz": -330
    },
    "id": "MsGdwX4ukmJg",
    "outputId": "5beb868f-34f8-4051-97ff-eb7c90819a17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# save_path = '/content/drive/MyDrive/Dl projects/RNN basics/Machine Translation'\n",
    "\n",
    "model_name1 = 'rnn_encoder_model'\n",
    "# model_path1 = save_path + '/' + model_name1\n",
    "encoder_model = tf.keras.models.load_model(model_name1)\n",
    "\n",
    "model_name2 = 'rnn_decoder_model'\n",
    "# model_path2 = save_path + '/' + model_name2\n",
    "decoder_model = tf.keras.models.load_model(model_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 338,
     "status": "ok",
     "timestamp": 1623679629138,
     "user": {
      "displayName": "NAKUL CHAMARIYA",
      "photoUrl": "",
      "userId": "06259338779627162060"
     },
     "user_tz": -330
    },
    "id": "MyFte3i0REKN",
    "outputId": "83e5dd5d-a43f-482b-a941-fc9d91ef09a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{1: '<OOV>', 2: ' ', 3: 'e', 4: 'i', 5: 'n', 6: 't', 7: 's', 8: 'h', 9: 'a', 10: 'r', 11: 'c', 12: 'm', 13: 'd', 14: 'u', 15: 'o', 16: 'l', 17: 'g', 18: 'b', 19: 'w', 20: 'f', 21: 'k', 22: 'z', 23: 'ü', 24: 'v', 25: 'p', 26: 'ä', 27: 'ö', 28: 'ß', 29: 'j', 30: 'y', 31: '’', 32: 'x', 33: '0', 34: '3', 35: '1', 36: 'q', 37: '2', 38: '„', 39: '“', 40: '8', 41: '9', 42: '\\xa0', 43: '5', 44: '6', 45: '7', 46: '4', 47: '\\u200b', 48: 'ō', 49: 'á', 50: '—', 51: '–', 52: '\\u202f', 0: 'padding'}\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.chdir(save_path)\n",
    "# print(os.getcwd())\n",
    "\n",
    "import joblib\n",
    "tags_dict = joblib.load('tags.joblib')\n",
    "word_tokenizer = joblib.load('tokenizer.joblib')\n",
    "\n",
    "print('\\n')\n",
    "print(tags_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import contractions\n",
    "import numpy as np\n",
    "\n",
    "def text_preprocess(s):\n",
    "    s = contractions.fix(s)\n",
    "    s = s.lower()\n",
    "    s = s.rstrip()\n",
    "    s = s.lstrip()\n",
    "\n",
    "    text = \"\"\n",
    "    for ch in s:\n",
    "        if ch not in string.punctuation:\n",
    "            text = text + ch\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(text, max_len, start_token, end_token, max_output_len, tags, word_tokenizer):\n",
    "    original_text = text\n",
    "    text = text_preprocess(text)\n",
    "\n",
    "    data = np.array(word_tokenizer.texts_to_sequences(text))\n",
    "    data = data.ravel()\n",
    "\n",
    "    data = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        [data], maxlen = max_len, padding = 'pre',\n",
    "        truncating='post', value=0.0 )\n",
    "  \n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = start_token\n",
    "    target_seq = target_seq.ravel()\n",
    "\n",
    "    encoder_outputs, h, c = encoder_model.predict(data)\n",
    "    states_value = [h,c]\n",
    "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value + [encoder_outputs])\n",
    "\n",
    "    output_sen = []\n",
    "    for _ in range(max_output_len):\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value + [encoder_outputs])\n",
    "        idx = np.argmax(output_tokens,axis=2).ravel()\n",
    "\n",
    "        if idx == end_token:\n",
    "            break\n",
    "        else:\n",
    "            output_sen.append(tags[idx[0]])\n",
    "\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = idx[0]\n",
    "        target_seq = target_seq.ravel()\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return original_text,''.join(output_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I am very Happy'\n",
    "max_len = 21\n",
    "start_token = 53\n",
    "end_token = 54\n",
    "max_output_len = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, output = translate_sentence(text, max_len, start_token, end_token, max_output_len, tags_dict, word_tokenizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am very Happy\n",
      "ich bin sehr glücklich\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = []\n",
    "input_list.append('Input text in English')\n",
    "input_list.append(text)\n",
    "\n",
    "output_list = []\n",
    "output_list.append('Translated text in German')\n",
    "output_list.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Input text in English', 'I am very Happy']\n",
      "['Translated text in German', 'ich bin sehr glücklich']\n"
     ]
    }
   ],
   "source": [
    "print(input_list)\n",
    "print(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pywebio.input import input,TEXT\n",
    "from pywebio.output import put_tabs,put_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output():\n",
    "    text = input('Machine Language Translation English to German',placeholder = \"Enter the text in English\", type = TEXT)\n",
    "    \n",
    "    max_len = 21\n",
    "    start_token = 53\n",
    "    end_token = 54\n",
    "    max_output_len = 120\n",
    "    text, output = translate_sentence(text, max_len, start_token, end_token, max_output_len, tags_dict, word_tokenizer) \n",
    "    \n",
    "    input_list = []\n",
    "    input_list.append('Input text in English')\n",
    "    input_list.append(text)\n",
    "\n",
    "    output_list = []\n",
    "    output_list.append('Translated text in German')\n",
    "    output_list.append(output)\n",
    "    \n",
    "    final_list = []\n",
    "    final_list.append(input_list)\n",
    "    final_list.append(output_list)\n",
    "    \n",
    "    put_table(final_list, header=['Description', 'Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Testing the model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
